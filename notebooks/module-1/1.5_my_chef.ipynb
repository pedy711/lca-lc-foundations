{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.messages import HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "from tavily import TavilyClient\n",
    "from typing import Dict, Any\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def web_search(query: str) -> Dict[str, Any]:\n",
    "    \"\"\"Search the web for information\"\"\"\n",
    "    return tavily_client.search(query)\n",
    "\n",
    "\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\"\n",
    "\n",
    "tavily_client = TavilyClient()\n",
    "\n",
    "model = init_chat_model(model=MODEL_NAME, model_provider=\"google_genai\")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "agent = create_agent(model=model,\n",
    "                     checkpointer=InMemorySaver(),\n",
    "                     tools=[web_search])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Upload fridge image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import FileUpload\n",
    "from IPython.display import display\n",
    "\n",
    "uploader = FileUpload(accept='.png', multiple=False)\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_file = uploader.value[0]\n",
    "\n",
    "content_mv = uploaded_file[\"content\"]\n",
    "img_bytes = bytes(content_mv)\n",
    "img_b64 = base64.b64encode(img_bytes).decode(\"utf-8\")\n",
    "\n",
    "multimodal_question = HumanMessage(content=[\n",
    "    {\"type\": \"text\", \"text\": \"Tell me about the image\"},\n",
    "    {\"type\": \"image\", \"base64\": img_b64, \"mime_type\": \"image/png\"}\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Record audio instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import io\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "duration = 5  # seconds\n",
    "sample_rate = 44100\n",
    "\n",
    "print(\"Recording...\")\n",
    "audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)\n",
    "for _ in tqdm(range(duration * 10)):\n",
    "    time.sleep(0.1)\n",
    "sd.wait()\n",
    "print(\"Done.\")\n",
    "\n",
    "buf = io.BytesIO()\n",
    "write(buf, sample_rate, audio)\n",
    "wav_bytes = buf.getvalue()\n",
    "\n",
    "aud_b64 = base64.b64encode(wav_bytes).decode(\"utf-8\")\n",
    "\n",
    "audio_question = HumanMessage(content=[\n",
    "    {\"type\": \"text\", \"text\": \"Write the transcript of the user's voice\"},\n",
    "    {\"type\": \"audio\", \"base64\": aud_b64, \"mime_type\": \"audio/wav\"}\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Invoke agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "userInstructionResponse = agent.invoke(\n",
    "    {\"messages\": [multimodal_question][-1].content}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_question = HumanMessage(content=[\n",
    "    {\"type\": \"text\", \"text\": [multimodal_question][-1].content},\n",
    "    {\"type\": \"image\", \"base64\": img_b64, \"mime_type\": \"image/png\"}\n",
    "])\n",
    "\n",
    "userImageResponse = agent.invoke(\n",
    "    {\"messages\": [image_question][-1].content}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
