{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Text input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "https://platform.openai.com/docs/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\"\n",
    "model = init_chat_model(model=MODEL_NAME, model_provider=\"google_genai\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You are a science fiction writer, create a capital city at the users request.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "question = HumanMessage(content=[\n",
    "    {\"type\": \"text\", \"text\": \"What is the capital of The Moon?\"}\n",
    "])\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [question]}\n",
    ")\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Image input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import FileUpload\n",
    "from IPython.display import display\n",
    "\n",
    "uploader = FileUpload(accept='.png', multiple=False)\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uploader.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "# Get the first (and only) uploaded file dict\n",
    "uploaded_file = uploader.value[0]\n",
    "\n",
    "# This is a memoryview\n",
    "content_mv = uploaded_file[\"content\"]\n",
    "\n",
    "# Convert memoryview -> bytes\n",
    "img_bytes = bytes(content_mv)  # or content_mv.tobytes()\n",
    "\n",
    "# Now base64 encode\n",
    "img_b64 = base64.b64encode(img_bytes).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "multimodal_question = HumanMessage(content=[\n",
    "    {\"type\": \"text\", \"text\": \"Tell me about the image\"},\n",
    "    {\"type\": \"image\", \"base64\": img_b64, \"mime_type\": \"image/png\"}\n",
    "])\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [multimodal_question]}\n",
    ")\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Audio input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import base64\n",
    "import io\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Recording settings\n",
    "duration = 5  # seconds\n",
    "sample_rate = 44100\n",
    "\n",
    "print(\"Recording...\")\n",
    "audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)\n",
    "# Progress bar for the duration\n",
    "for _ in tqdm(range(duration * 10)):   # update 10Ã— per second\n",
    "    time.sleep(0.1)\n",
    "sd.wait()\n",
    "print(\"Done.\")\n",
    "\n",
    "# Write WAV to an in-memory buffer\n",
    "buf = io.BytesIO()\n",
    "write(buf, sample_rate, audio)\n",
    "wav_bytes = buf.getvalue()\n",
    "\n",
    "aud_b64 = base64.b64encode(wav_bytes).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "multimodal_question = HumanMessage(content=[\n",
    "    {\"type\": \"text\", \"text\": \"Follow the audio instruction\"},\n",
    "    {\"type\": \"audio\", \"base64\": aud_b64, \"mime_type\": \"audio/wav\"}\n",
    "])\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [multimodal_question]}\n",
    ")\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
